
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
    <link rel="shortcut icon" href="myIcon.ico">
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="keywords" content="Tao Huang, SenseTime">
    <meta name="description" content="Tao Huang's home page">
    <link rel="stylesheet" href="jemdoc.css" type="text/css" />
    <title>Tao Huang</title>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-39824124-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script');
        ga.type = 'text/javascript';
        ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(ga, s);
    })();
    </script>
</head>

<body>
    <div id="layout-content" style="margin-top:25px">
        <table>
            <tbody>
                <tr>
                    <td width="700">
                        <div id="toptitle">
                        <!--<h1>Tao Huang &nbsp; <img src="assets/name_chs.png" height="40px" style="margin-bottom:-10px"></h1>-->
                        <h1>Tao Huang</h1>
				</div>
				<h3>Researcher</h3>
				<p>
                    SenseTime Group Ltd</br>
					Email: <a href="mailto:hunto@foxmail.com">hunto [at] foxmail.com</a>
					or <a href="mailto:huangtao@sensetime.com">huangtao [at] sensetime.com</a>
				</p>
				<p>
					<a href="https://github.com/hunto"><img src="assets/github.png" height="30px"></a>
					<a href="https://scholar.google.com/citations?user=jkcRdBgAAAAJ&hl=en"><img src="assets/google_scholar.png" height="30px"></a>
				</p>
			</td>
			<td><img src="assets/taohuang.jpg" border="0" height="200"></br></td>
		<tr>
	</tbody>
</table>

<h2>Biography [<a href="assets/CV_taohuang.pdf">CV</a>]</h2>
<!-- <h2>Biography</h2> -->
<p>
    <div style="text-align:justify"> 
        I am currently a Researcher at <a href="https://sensetime.com">SenseTime</a>, working with <a href="https://shanyou92.github.io/">Shan You</a> and <a href="http://wangfei.info/">Fei Wang</a>. Before that, I obtained my B.E degree in the <a href="http://cs.hust.edu.cn">School of Computer Science and Technology</a>, <a href="https://www.hust.edu.cn">Huazhong University of Science and Technology</a> in Jun. 2020. 
    </div>
</p>
<p>My research interests include AutoML and other computer vision tasks, such as face recognition and object detection.</p>
<!-- <p><font color="red">Pinned: </font></p> -->
<h2>News</h2>
<ul>
    <li>
        [2020/11] One paper about NAS was released on <a href="https://arxiv.org/abs/2011.09300">arXiv</a>. Our TopoNAS explicitly learns the topology for differentiable NAS (DARTS), and enjoys significant efficiency improvement on obtained architectures.
    </li>
    <li>
        [2020/10] One paper about quantum architecture search(QAS) was released on <a href="https://arxiv.org/abs/2010.10217">arXiv</a>. Our QAS implicitly learns a rule that can well suppress the influence of quantum noise and the barren plateau.
    </li>
    <li>
        [2020/02] One paper about NAS was accepted to CVPR2020.
    </li>
</ul>

<h2>Publications [<a href="https://scholar.google.com/citations?user=jkcRdBgAAAAJ&hl=en">Google Scholar</a>]</h2>
*: equal contribution.
<ul>
	<li>
		<a href="https://arxiv.org/abs/2003.11236">GreedyNAS: Towards Fast One-Shot NAS with Greedy Supernet</a><br>
		Shan You*, <b>Tao Huang*</b>, Mingmin Yang*, Fei Wang, Chen Qian, and Changshui Zhang.<br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2020.</br>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/pdf/2003.11236.pdf">Paper</a>]
			[<a href="https://scholar.googleusercontent.com/scholar.bib?q=info:QKR5FE1vJJ8J:scholar.google.com/&output=citation&scisdr=CgXAStp0EJaUt2QhhGg:AAGBfm0AAAAAX5EknGjGpghm1148zi-28e1gsbxNtymj&scisig=AAGBfm0AAAAAX5EknPwfhTlRNR_VvrHDzl0KwAIO_sb4&scisf=4&ct=citation&cd=-1&hl=en">Bib</a>]
		</p>
	</li>
</ul>

<h2>Experience</h2>
<ul>
	<li>
        <a href="https://sensetime.com">SenseTime</a>, Beijing, China<br>
        <div style="float:left; text-align:left">
            Researcher</div> <div style="float:right; text-align:right">Jul. 2020 – Now
            </div><br>
        <div style="float:left; text-align:left">
            Research Intern</div> <div style="float:right; text-align:right">Aug. 2019 – Jul. 2020
            </div><br>
        <ul>
            <li>
                Research on neural architecture search(NAS) and channel pruning.
            </li>
            <li>
                Applied NAS to face verification task on large­scale industrial datasets, which significantly improves the performance.
            </li>
        </ul>
	</li>
	<li>
		<div style="float:left; text-align:left"><a href="https://horizon.ai">Horizon Robotics</a>, Beijing, China</div> <div style="float:right; text-align:right">May 2019 – Aug. 2019</div><br>
        Computer Vision Research Intern<br>
        <ul>
            <li>
                Development of object detection framework: anchor­free detection method, detection in traffic scene.
            </li>
            <li>
                Research on knowledge distillation methods for face alignment, object detection.
            </li>
        </ul>
	</li>
	<li>
        <a href="http://dian.org.cn/">Dian Group</a>, Wuhan, Hubei province, China<br>
        <div style="float:left; text-align:left">Team Leader of Real­time Face Detection & Alignment Project, AI Group</div> <div style="float:right; text-align:right">Nov. 2018 – May 2019</div><br>
        <ul>
            <li>
                Develop Android APP to inference face detection, tracking and 106­point landmark models on mobile devices. 
            </li>
            <li>
                Research on model acceleration (e.g., knowledge distillation, model pruning) and facial landmark (e.g., multi­task learning, loss function, augmentation).
            </li>
            <li>
                Our proposed model archieves 5 ms / image inference speed on Huawei Mate20 Pro.
            </li>
        </ul>
        <div style="float:left; text-align:left">Core Member of Beibei Intelligent Customer Service Project, AI Group</div> <div style="float:right; text-align:right">Feb. 2018 – Nov. 2018</div><br>
        <ul>
            <li>
                This project comes from <a href="https://www.beibei.com/">Beibei Group Company</a>, Beibei is the bigest mother­baby E­commerce platform in China. The task is to find an optimal answer based on classification of customer questions.
            </li>
            <li>
                Research and development on text classification and data augmentation, etc.
            </li>
        </ul>
	</li>
	<li>
		<div style="float:left; text-align:left">3D Printer Team, Wuhan, Hubei province, China</div> <div style="float:right; text-align:right">Jan. 2017 – Jan. 2019</div><br>
		Group Learder of Embedded Control Group<br>
		Topic: developing control algorithms for 3DP/FDM 3D printers<br>
	</li>
</ul>

<!-- <h2>Professional Activities</h2> -->
<!-- <ul> -->
	<!---<li>Conference Reviewer: ICCV 2017, CVPR 2018, ECCV 2018, ACCV 2018, CVPR 2019, ICCV 2019, IV 2019, BMVC 2019, NIPS 2019.</li>--->
	<!-- <li>Conference Reviewer:<br> -->
		<!-- &emsp; IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2021.</li> -->
<!-- </ul> -->

<h2>Honors & Awards</h2>
<ul>
	<li>
		<div style="float:left; text-align:left">Outstanding Graduate award, Huazhong University of Science and Technology</div> <div style="float:right; text-align:right">Jun. 2020</div>
    </li>
    <li>
		<div style="float:left; text-align:left">Outstanding Graduate Thesis award, Huazhong University of Science and Technology</div> <div style="float:right; text-align:right">Jun. 2020</div>
    </li>
    <li>
		<div style="float:left; text-align:left">The First Prize of National College Student Connected Smarter System Innovation Competition, National</div> <div style="float:right; text-align:right">2018</div>
	</li>
    <li>
		<div style="float:left; text-align:left">Third Class Prize, ‘Challenge Cup’ Competition, Provincial</div> <div style="float:right; text-align:right">2018</div>
	</li>
	<li>
		<div style="float:left; text-align:left">First Class Prize, ‘Challenge Cup’ Competition, HUST</div> <div style="float:right; text-align:right">2018</div>
	</li>
</ul>

<div id="footer">
	<div id="footer-text"></div>
</div>
	<center>© Tao Huang | Last updated: 10/22/2020</center>
    <!--<center>© Tao Huang
    	<script type="text/javascript" language="javascript">
    	if (Date.parse(document.lastModified) != 0) document.write(" | Last updated: " + document.lastModified);</script>
    </center>-->
</div>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88615920-1', 'auto');
  ga('send', 'pageview');

</script>

</div>
</body>
</html>