
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5.0, minimum-scale=0.2">


<head>
    <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101296995);</script>
    <script async src="//static.getclicky.com/js"></script>    

    <script>
        try{
            if (window.screen.width < 700) {
                setActiveStyleSheet("jemdoc_mobile.css"); 
            } 
            else if(/iPad/i.test(navigator.userAgent)){ 
                setActiveStyleSheet("jemdoc.css"); 
            } 
            else{
                setActiveStyleSheet("jemdoc.css"); 
            } 
        } 
        catch(e){} 

        function setActiveStyleSheet(filename){
            document.write("<link href="+filename+" rel=stylesheet>");
        }

        function checkFilter(type, li) {
            if (type == "All") {
                return true
            }
            else if (type == "First-authored") {
                res = li.getAttribute("first_authored")
                return res
            }
            else {
                cate = li.getAttribute("category")
                if (!cate) {
                    return false
                }
                items = cate.split(',')
                for (j = 0; j < items.length; j++) {
                    console.log(items[j])
                    if (type.toUpperCase() == items[j].toUpperCase()) {
                        return true
                    }
                }
                return false
            }
        }

        function filterPub(type) {
            ul = document.getElementById("publications")
            li = ul.getElementsByTagName("li")
            for (i = 0; i < li.length; i++) {
                if (!checkFilter(type, li[i])) {
                    li[i].style.display = "none";
                }
                else {
                    li[i].style.display = ""
                }
            }
            // change the button color
            bts = document.getElementsByClassName("filter")
            for (k = 0; k < bts.length; k++) {
                if (bts[k].textContent == type) {
                    bts[k].style.setProperty("--color", "#000")
                    bts[k].style.setProperty("--border", "#000")
                    // bts[k].style.color = "#000"
                }
                else {
                    bts[k].style.setProperty("--color", "#a0a0a0")
                    bts[k].style.setProperty("--border", "#d3d3d3")
                    // bts[k].style.color = "#a0a0a0"
                }
            }
        }

    </script>

    <script>
        // import data from './bibtex.json' assert { type: 'json' };
        const data = {
"huang2023masked": `@inproceedings{
huang2023masked,
title={Masked Distillation with Receptive Tokens},
author={Tao Huang and Yuan Zhang and Shan You and Fei Wang and Chen Qian and Jian Cao and Chang Xu},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=mWRngkvIki3}
}`,
"NEURIPS2022_da669dfd": `@inproceedings{NEURIPS2022_da669dfd,
 author = {Huang, Tao and You, Shan and Wang, Fei and Qian, Chen and Xu, Chang},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {33716--33727},
 publisher = {Curran Associates, Inc.},
 title = {Knowledge Distillation from A Stronger Teacher},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/da669dfd3c36c93905a17ddba01eef06-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}`
        }

        function getBibTex(key) {
            prompt("You can copy the text manually.", data[key]);
        }
    </script>

    <link rel="shortcut icon" href="myIcon.ico">
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="keywords" content="Yuan Zhang, 张袁, Alibaba DAMO, Peking University, PKU, Hohai University, HHU">
    <meta name="description" content="Homepage of Yuan Zhang">
    <!-- <link rel="stylesheet" href="jemdoc.css" type="text/css" />
    <link rel="stylesheet" media="screen and (max-width:700px)" href="jemdoc_mobile.css" type="text/css" />
    <link rel="stylesheet" media="screen and (max-width:700px)" href="jemdoc.css" type="text/css" /> -->
    <title>Homepage of Yuan Zhang</title>
</head>

<body>
    <div id="layout-content" style="margin-top:0px">
        <table>
            <tbody>
                <tr>
                    <td width="60%" class="tdw" border="0">
                        <div id="toptitle">
                            <h1>Yuan &nbsp;Zhang</h1>
				        </div>
                        <p>
                            Algorithm Engineer <br>
                            ByteDance AML
                        </p>
                        <p>
                            Email: <a href="mailto:zhangyuan@stu.pku.edu.cn">zhangyuan [at] stu.pku.edu.cn</a>
                        </p>
                        <p>
                            <a href="https://github.com/Gumpest"><img src="assets/github.png" class="icon"></a>&nbsp;&nbsp;
                            <a href="https://scholar.google.com/citations?user=dXj1WskAAAAJ&hl=en"><img src="assets/google_scholar.png" class="icon"></a>
                        </p>
                        <!-- <b>Control the controllable, observe the observable, leave the rest alone.</b> -->
                    </td>
                    <td width="20%"><img src="assets/taohuang.png" border="0" width="100%"></br></td>
			        
		<tr>
	</tbody>
</table>


<h2>Biography</h2>
<p>
    <div style="text-align:justify"> 
	Yuan Zhang is currently an algorithm engineer in ByteDance AML. Before that, he received his 
	Master degree in <a href="https://english.pku.edu.cn/">Peking University (PKU)</a>, 
	under the supervision of <a href="http://www.aipku.cn/">Prof. Jian Cao</a>,
	and received his Bachelor degree in Hohai University.<br />
    </div>
</p>
<p>His major research interests lie within computer vision and model compression, such as
	<ul>
		<li style="margin-top: 0.2em">Light Weight Object Detection</li>
		<li style="margin-top: 0.2em">Knowledge Distillation (KD)</li>
		<li style="margin-top: 0.2em">Transformer for Sequences</li>
	</ul>
</p>

<h2>Education</h2>
<ul>
	<li>
		<a href="https://english.pku.edu.cn/">Peking University (PKU)</a>, Beijing, China<br>
		<div style="display: flex; justify-content: space-between; font-style: italic;">
		    <div> Master Degree.</div>	
		    <div style="margin-right: 2px;">Sep. 2020 – Jun. 2023</div>
		</div>
		<ul>
		    <li style="margin-top: 0.3em">
			Rank: 3/110
		    </li>
		    <li style="margin-top: 0.3em">
			National Scholarship of China
		    </li>
		</ul>
	</li>
	<li>
		<a href="https://en.hhu.edu.cn/">Hohai University (HHU)</a>, Nanjing, China <br>
		<div style="display: flex; justify-content: space-between; font-style: italic;">
		    <div> Bachelor Degree.</div>	
		    <div style="margin-right: 2px;">Sep. 2016 – Jun. 2020</div>
		</div>
		<ul>
		    <li style="margin-top: 0.3em">
			Rank: 1/112
		    </li>
		    <li style="margin-top: 0.3em">
			National Scholarship of China
		    </li>
		</ul>
	</li>
</ul>

<h2>Research Experience</h2>
<ul>
	<li>
        <a href="https://www.bytedance.com/en/">ByteDance AML (Applied Machine Learning)</a>, Beijing, China<br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Research Intern  (Advisor: Zhe Chen</a>).</div>
            <div style="margin-left: 2px;">Feb. 2023 – Now</div>
        </div>

        <ul>
            <li style="margin-top: 0.3em">
                Research on transformer for sequence learning in Douyin.
            </li>
            <li style="margin-top: 0.3em">
                Estimate CTR (Click-through-ratio) in Douyin Advertisement and Live.
            </li>
        </ul>
	</li>	

	<li>
        <a href="https://damo.alibaba.com/?lang=en">Alibaba DAMO Academy</a>, Beijing, China<br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Research Intern  (Advisor: <a href="http://cwhgn.github.io/">Weihua Chen</a>).</div>
            <div style="margin-left: 2px;">Jun. 2022 – Feb. 2023</div>
        </div>

        <ul>
            <li style="margin-top: 0.3em">
                Research on knowledge distillation (KD) and propose AKD.
            </li>
            <li style="margin-top: 0.3em">
                Distill for DAMO-YOLO.
            </li>
        </ul>
	</li>
  
	<li>
        <a href="https://sensetime.com">SenseTime Research</a>, Beijing, China<br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Research Intern  (Advisor: <a href="https://taohuang.info/">Tao Huang</a>).</div>
            <div style="margin-left: 2px;">Mar. 2022 – Jun. 2022</div>
        </div>
        <ul>
            <li style="margin-top: 0.3em">
                Research on knowledge distillation (KD) and propose MasKD.
            </li>
            <li style="margin-top: 0.3em">
                Develop on MMRazor.
            </li>
        </ul>
	</li>

</ul>


<h2>Publications</h2>
*: equal contribution.<br>
First-authored papers: <venue>ACM MM</venue>x 1, <venue>ICLR</venue>x 1, <venue>ICASSP</venue>x 1 <br><br>

<button class="filter" type="button" onclick="filterPub('All')" style="--color: #000; --border: #000">All</button>&nbsp;
<button class="filter" type="button" onclick="filterPub('First-authored')">First-authored</button>&nbsp;
<button class="filter" type="button" onclick="filterPub('KD')">KD</button>&nbsp;

<ul id="publications">
    <li first_authored=true category="KD">
        <venue>ACM MM</venue><pt>Avatar Knowledge Distillation: Self-ensemble Teacher Paradigm with Uncertainty</pt><br>
        <b>Yuan Zhang</b><g>, Weihua Chen*, Yichen Lu*, Tao Huang, Xiuyu Sun, Jian Cao</g><br>
        <em>Proceedings of the 31th ACM International Conference on Multimedia</em> (<b>ACM MM</b>), 2023.
        <p>
		<a href="https://arxiv.org/abs/2305.02722" class="button-59">ArXiv</a>
		<a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=9322121606680381236" class="button-59">Bib</a>
		<a class="button-59" href="https://github.com/Gumpest/AvatarKD">Code</a>
        </p>
    </li>
    <li first_authored=true category="KD">
	<venue>ICLR</venue><pt>Masked Distillation with Receptive Tokens</pt><br>
	<g>Tao Huang*,</g> <b>Yuan Zhang*</b><g>, Shan You, Fei Wang, Chen Qian, Jian Cao, Chang Xu</g><br>
	<em>International Conference on Learning Representations</em> (<b>ICLR</b>), 2023.</em>
	<p>
		<a class="button-59" href="https://arxiv.org/abs/2205.14589">ArXiv</a>
		<button class="button-59" onclick="getBibTex('huang2023masked')">Bib</button>
		<a class="button-59" href="https://github.com/hunto/MasKD">Code</a>
	</p>
    </li>
    <li first_authored=true category="KD">
		<venue>NeurIPS</venue><pt>Knowledge Distillation from A Stronger Teacher</pt><br>
		<b>Tao Huang</b><g>, Shan You, Fei Wang, Chen Qian, Chang Xu</g><br>
        <em>Advances in Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2022.
		<p>
			<a href="https://arxiv.org/abs/2205.10536" class="button-59">ArXiv</a>
			<button class="button-59" onclick="getBibTex('NEURIPS2022_da669dfd')">Bib</button>
            <a href="https://github.com/hunto/DIST_KD" class="button-59">Code</a>
            <a href="assets/dist/KD_sharing_Tao_20220715.pdf" class="button-59">Slides</a>
            <a href="https://mp.weixin.qq.com/s/PwzyaZXCrl_W8NmiQgXm0g" class="button-59">解读</a>
		</p>
    </li>
    <li category="NAS">
		<venue>NPJ QI</venue><pt></pt><pt>Quantum circuit architecture search for variational quantum algorithms</pt><br>
		<g>Yuxuan Du,</g> <b>Tao Huang</b><g>, Shan You, Min-Hsiu Hsieh, Dacheng Tao</g><br>
		<em>Nature Partner Journals Quantum Information</em> (<b>NPJ QI</b>), 2022.<br>
		<p>
			<a href="https://arxiv.org/abs/2010.10217" class="button-59">ArXiv</a>
			<a href="https://scholar.google.com/scholar?cluster=14041544508923660633&hl=en&as_sdt=0,5" class="button-59">Bib</a>
			<a href="https://github.com/yuxuan-du/Quantum_architecture_search" class="button-59">Code</a>
		</p>
    </li>
    <li first_authored=true category="NAS">
		<venue>CVPR</venue><pt></pt><pt>GreedyNASv2: Greedier Search with a Greedy Path Filter</pt><br>
		<b>Tao Huang</b><g>, Shan You, Fei Wang, Chen Qian, Changshui Zhang, Xiaogang Wang, Chang Xu</g><br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2022.<br>
		<p>
			<a href="https://arxiv.org/abs/2111.12609" class="button-59">ArXiv</a>
			<a href="https://scholar.google.com/scholar?cluster=8646649449956447640&hl=en&as_sdt=0,5" class="button-59">Bib</a>
		</p>
    </li>
    <li first_authored=true>
        <venue>CVPR</venue><pt>DyRep: Bootstrapping Training with Dynamic Re-parameterization</pt><br>
        <b>Tao Huang</b><g>, Shan You, Bohan Zhang, Yuxuan Du, Fei Wang, Chen Qian, Chang Xu</g><br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2022.<br>
        <p>
            <a href="https://arxiv.org/abs/2203.12868" class="button-59">ArXiv</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=9004725926464672087" class="button-59">Bib</a>
            <a href="https://github.com/hunto/DyRep" class="button-59">Code</a>
		</p>
    </li>
    <li first_authored=true>
        <venue>ICLR</venue><pt>Relational Surrogate Loss Learning</pt><br>
        <b>Tao Huang</b><g>, Zekang Li, Hua Lu, Yong Shan, Shusheng Yang, Yang Feng, Fei Wang, Shan You, Chang Xu</g><br>
        <em>International Conference on Learning Representations</em> (<b>ICLR</b>), 2022.<br>
        <p>
			<a href="https://arxiv.org/abs/2202.13197" class="button-59">ArXiv</a>
            <a href="https://openreview.net/forum?id=dZPgfwaTaXv" class="button-59">Bib</a>
            <a href="https://github.com/hunto/ReLoss" class="button-59">Code</a>
            <a href="assets/reloss/Poster_ICLR2022_ReLoss.pdf" class="button-59">Poster</a>
            <a href="assets/reloss/Slides_ICLR2022_ReLoss.pdf" class="button-59">Slides</a>
		</p>
    </li>
    <li category="pruning">
		<venue>ICASSP</venue><pt>Data Agnostic Filter Gating for Efficient Deep Networks</pt><br>
        <g>Hongyan Xu, Xiu Su, Shan You,</g> <b>Tao Huang</b><g>, Fei Wang, Chen Qian, Changshui Zhang, Chang Xu, Dadong Wang, Arcot Sowmya</g><br>
		<em>IEEE International Conference on Acoustics, Speech and Signal Processing</em> (<b>ICASSP</b>), 2022.
		<p>
			<a href="https://arxiv.org/abs/2010.15041" class="button-59">ArXiv</a>
			<a href="https://scholar.google.com/scholar?cluster=6802250960153223046&hl=en&as_sdt=0,5" class="button-59">Bib</a>
		</p>
	</li>
    <li first_authored=true category="NAS">
        <venue>CVPR</venue><pt>Prioritized Architecture Sampling with Monto-Carlo Tree Search</pt><br>
        <g>Xiu Su*,</g> <b>Tao Huang</b>*<g>, Yanxi Li, Shan You, Fei Wang, Chen Qian, Changshui Zhang, Chang Xu</g><br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2021.<br>
        <p>
			<a href="https://arxiv.org/abs/2103.11922" class="button-59">ArXiv</a>
            <a href="assets/mctnas/Poster_CVPR2021_MCT-NAS.pdf" class="button-59">Poster</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=16897259555170724856" class="button-59">Bib</a>
            <a href="https://github.com/xiusu/NAS-Bench-Macro" class="button-59">NAS-Bench-Macro</a>
		</p>
    </li>
    <li category="NAS,pruning">
        <venue>ICLR</venue><pt>Locally Free Weight Sharing for Network Width Search</pt><br>
        <g>Xiu Su, Shan You,</g> <b>Tao Huang</b><g>, Fei Wang, Chen Qian, Changshui Zhang, Chang Xu</g><br>
        <em>International Conference on Learning Representations</em> (<b>ICLR, Spotlight</b>), 2021.<br>
        <p>
			<a href="https://arxiv.org/abs/2102.05258" class="button-59">ArXiv</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=13852905600525060682" class="button-59">Bib</a>
            <a href="https://openreview.net/forum?id=S0UdquAnr9k" class="button-59">OpenReview</a>
		</p>
    </li>
	<li first_authored=true category="NAS">
		<venue>CVPR</venue><pt>GreedyNAS: Towards Fast One-Shot NAS with Greedy Supernet</pt><br>
        <g>Shan You*,</g> <b>Tao Huang</b>*<g>, Mingmin Yang*, Fei Wang, Chen Qian, Changshui Zhang</g><br>
		<em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2020.</br>
		<p>
			<a href="https://arxiv.org/abs/2003.11236" class="button-59">ArXiv</a>
            <a href="https://scholar.google.com/scholar?cluster=11467412928038806592&hl=en&as_sdt=0,5" class="button-59">Bib</a>
            <a href="assets/greedynas/Poster_CVPR2020_GreedyNAS.pdf" class="button-59">Poster</a>
            <a href="assets/greedynas/Video_CVPR2020_GreedyNAS.mp4" class="button-59">Video</a>
            <a href="assets/greedynas/Slides_GreedyNAS_titan.pdf" class="button-59">Slides</a>
            <a href="https://github.com/open-mmlab/mmrazor" class="button-59">Code</a>
		</p>
	</li>
</ul>

<h2>Manuscripts</h2>
<ul>
    <li>
        <venue>arXiv</venue><pt>Positive Label Is All You Need for Multi-Label Classification</pt><br>
        <g>Zhixiang Yuan, Kaixin Zhang, </g><b>Tao Huang</b><br>
        <em>arXiv preprint arXiv:2306.16016 (2023).</em>
        <p>
            <a href="https://arxiv.org/abs/2306.16016" class="button-59">ArXiv</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=11695637510257123983" class="button-59">Bib</a>
        </p>
    </li>
    <li category="KD">
        <venue>arXiv</venue><pt>Knowledge Diffusion for Distillation</pt><br>
        <b>Tao Huang</b><g>, Yuan Zhang, Mingkai Zheng, Shan You, Fei Wang, Chen Qian, Chang Xu</g><br>
        <em>arXiv preprint arXiv:2305.15712 (2023).</em>
        <p>
            <a href="https://arxiv.org/abs/2305.15712" class="button-59">ArXiv</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=4615443208731882220" class="button-59">Bib</a>
            <a href="https://github.com/hunto/DiffKD" class="button-59">Code</a>
        </p>
    </li>
    <li>
        <venue>arXiv</venue><pt>LightViT: Towards Light-Weight Convolution-Free Vision Transformers</pt><br>
        <b>Tao Huang</b><g>, Lang Huang, Shan You, Fei Wang, Chen Qian, Chang Xu</g><br>
        <em>arXiv preprint arXiv:2207.05557 (2022).</em>
        <p>
            <a href="https://arxiv.org/abs/2207.05557" class="button-59">ArXiv</a>
            <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=13876321258274905912" class="button-59">Bib</a>
            <a href="https://github.com/hunto/LightViT" class="button-59">Code</a>
        </p>
    </li>
    <li>
		<venue>arXiv</venue><pt>Explicitly Learning Topology for Differentiable Neural Architecture Search</pt><br>
		<b>Tao Huang</b><g>, Shan You, Yibo Yang, Zhuozhuo Tu, Fei Wang, Chen Qian, Changshui Zhang</g><br>
		<em>arXiv preprint arXiv:2011.09300 (2020).</em>
		<p>
			<a href="https://arxiv.org/abs/2011.09300" class="button-59">ArXiv</a>
			<a href="https://scholar.google.com/scholar?cluster=239245335818813796&hl=en&as_sdt=0,5" class="button-59">Bib</a>
		</p>
    </li>
</ul>

<!-- <h2>Manuscripts [<a href="https://scholar.google.com/citations?user=jkcRdBgAAAAJ&hl=en">Google Scholar</a>]</h2> -->
<!-- <h2>Manuscripts</h2> -->
<!-- <ul> -->
    <!-- <li>
		<pt>Explicitly Learning Topology for Differentiable Neural Architecture Search</pt><br>
		<b>Tao Huang</b>, Shan You, Yibo Yang, Zhuozhuo Tu, Fei Wang, Chen Qian, Changshui Zhang<br>
		<em>arXiv preprint arXiv:2011.09300 (2020).</em>
		<p style="margin-top:3px">
			[<a href="https://arxiv.org/abs/2011.09300">ArXiv</a>]
			[<a href="https://scholar.google.com/scholar?cluster=239245335818813796&hl=en&as_sdt=0,5">Bib</a>]
		</p>
    </li> -->
<!-- </ul> -->

<h2>Academic Services</h2>
<b>Reviewer for Conferences:</b>
<ul>
    <li style="margin-top: 0.2em">
        Neural Information Processing Systems (<b>NeurIPS</b>), 2021-2023.
    </li>
    <li style="margin-top: 0.2em">
        International Conference on Learning Representations (<b>ICLR</b>), 2023.
    </li>
    <li style="margin-top: 0.2em">
        International Conference on Machine Learning (<b>ICML</b>), 2022-2023.
    </li>
    <li style="margin-top: 0.2em">
        Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022-2023.
    </li>
    <li style="margin-top: 0.2em">
        International Conference on Computer Vision (<b>ICCV</b>), 2023.
    </li>
    <li style="margin-top: 0.2em">
        AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2023-2024.
    </li>
    <li style="margin-top: 0.2em">
        ACM International Conference on Multimedia (<b>ACM MM</b>), 2021-2023.
    </li>
</ul>

<b>Reviewer for Journals:</b>
<ul>
    <li style="margin-top: 0.2em">
        IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>)
    </li>
    <li style="margin-top: 0.2em">
        IEEE Transactions on Image Processing (<b>TIP</b>)
    </li>
</ul>

<h2>Talks</h2>
<ul>
    <li>TMLR Young Scientist Seminar@HKBU: "Knowledge Distillation from A Stronger Teacher", Jul. 2022. [<a href="assets/dist/KD_sharing_Tao_20220715.pdf">Slides</a>]</li>
</ul>

<h2>Education</h2>
<ul>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div><a href="https://www.sydney.edu.au/">The University of Sydney</a>, Sydney, Australia</div>
            <div style="margin-left: 2px;">July. 2022 – Present</div>
        </div>
        Ph.D. student at School of Computer Science<br>
        Advisor: <a href="http://changxu.xyz">Prof. Chang Xu</a><br>
    </li>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div><a href="https://www.hust.edu.cn">Huazhong University of Science and Technology</a>, Wuhan, China</div>
            <div style="margin-left: 2px;">Sep. 2016 – Jun. 2020</div>
        </div>
        B.E. in Computer Science and Technology<br>
    </li>
</ul>

<h2>Selected Experience</h2>
<ul>
	<!-- <li>
        <a href="https://sensetime.com">SenseTime</a>, Beijing, China<br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Research Intern</div>
            <div style="margin-left: 2px;">Jul. 2022 - Present</div>
        </div>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Researcher</div>
            <div style="margin-left: 2px;">Jul. 2020 – Jun. 2022</div>
        </div>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Research Intern</div>
            <div style="margin-left: 2px;">Aug. 2019 – Jul. 2020</div>
        </div>
        <ul>
            <li style="margin-top: 0.2em">
                Research on model compression algorithms (NAS, KD, pruning, etc.).
            </li>
            <li style="margin-top: 0.2em">
                Research and development on auto-driving (smart carbin) scenes such as face verification and drowsiness detection.
            </li>
            <li style="margin-top: 0.2em">
                Applied NAS to face verification task on large­scale industrial datasets, which significantly improves the performance.
            </li>
        </ul>
	</li>
	<li>
        <a href="https://horizon.ai">Horizon Robotics</a>, Beijing, China
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Computer Vision Research Intern</div>
            <div style="margin-left: 2px;">May 2019 – Aug. 2019</div>
        </div>
        <ul>
            <li style="margin-top: 0.2em">
                Development on object detection framework: anchor-­free detection method, detection in traffic scene.
            </li>
            <li style="margin-top: 0.2em">
                Research on knowledge distillation methods for face alignment, object detection.
            </li>
        </ul>
	</li> -->
	<li>
        <a href="http://dian.org.cn/">Dian Group</a>, Wuhan, Hubei province, China<br>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Team Leader of Real­time Face Detection & Alignment Project, AI Group</div>
            <div style="margin-left: 2px;">Nov. 2018 – May 2019</div>
        </div>
        <ul>
            <li style="margin-top: 0.2em">
                Develop Android APP to inference face detection, tracking, and 106-­point landmark models on mobile devices. 
            </li>
            <li style="margin-top: 0.2em">
                Research on model acceleration (e.g., knowledge distillation, model pruning) and facial landmark (e.g., multi­task learning, loss function, augmentation).
            </li>
            <li style="margin-top: 0.2em">
                Our proposed model archieves an inference speed of 5 ms / image on Huawei Mate20 Pro.
            </li>
        </ul>
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Core Member of Beibei Intelligent Customer Service Project, AI Group</div>
            <div style="margin-left: 2px;">Feb. 2018 – Nov. 2018</div>
        </div>
        <ul>
            <li style="margin-top: 0.2em">
                This project comes from <a href="https://www.beibei.com/">Beibei Group Company</a>, Beibei is the bigest mother-­baby ecommerce platform in China. The task is to find optimal answers based on classifications of customer questions.
            </li>
            <li style="margin-top: 0.2em">
                Research and development on text classification and data augmentation, etc.
            </li>
        </ul>
	</li>
	<li>
        3D Printer Team, Wuhan, Hubei province, China
        <div style="display: flex; justify-content: space-between; font-style: italic;">
            <div>Group Learder of Embedded Control Group</div>
            <div style="margin-left: 2px;">Oct. 2016 – Jan. 2019</div>
        </div>
		Topic: developing control algorithms for 3DP/FDM 3D printers<br>
	</li>
</ul>


<h2>Selected Awards</h2>
<ul>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div>Outstanding Graduate award, Huazhong University of Science and Technology</div>
            <div style="margin-left: 2px;">Jun. 2020</div>
        </div>
    </li>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div>Outstanding Graduate Thesis award, Huazhong University of Science and Technology</div>
            <div style="margin-left: 2px;">Jun. 2020</div>
        </div>
    </li>
    <!-- <li>
        <div style="display: flex; justify-content: space-between;">
            <div>First Class Prize, National College Student Connected Smarter System Innovation Competition, National</div>
            <div style="margin-left: 2px;">2018</div>
        </div>
    </li>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div>Third Class Prize, "Challenge Cup" Competition, Provincial</div>
            <div style="margin-left: 2px;">2018</div>
        </div>
    </li>
    <li>
        <div style="display: flex; justify-content: space-between;">
            <div>First Class Prize, "Challenge Cup" Competition, HUST</div>
            <div style="margin-left: 2px;">2018</div>
        </div>
    </li> -->
</ul>

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=n&d=53IqZwoIImQV5s-5apExUkXvB1IyVVtE-c4Z3rFA3P4&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>

<div id="footer">
	<div id="footer-text" style="text-align: center;">© Tao Huang | Last updated: July 6, 2023</div>
</div>
	<!-- <center>© Tao Huang | Last updated: 02/19/2021</center> -->
    <!--<center>© Tao Huang
    	<script type="text/javascript" language="javascript">
    	if (Date.parse(document.lastModified) != 0) document.write(" | Last updated: " + document.lastModified);</script>
    </center>-->
</div>

</body>

<script>
    var coll = document.getElementsByClassName("collapsible");
    var i;

    for (i = 0; i < coll.length; i++) {
        coll[i].addEventListener("click", function() {
            this.classList.toggle("active");
            var content = this.nextElementSibling;
            if (content.style.display === "block") {
            content.style.display = "none";
            } else {
            content.style.display = "block";
            }
        });
    }
</script>

</html>

